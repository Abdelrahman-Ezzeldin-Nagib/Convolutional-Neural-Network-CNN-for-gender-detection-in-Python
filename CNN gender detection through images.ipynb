{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage import color\n",
    "man_train = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\train\\man\\*\")\n",
    "woman_train = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\train\\woman\\*\")\n",
    "man_test = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\test\\man\\*\")\n",
    "woman_test = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\test\\woman\\*\")\n",
    "man_val = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\valid\\man\\*\")\n",
    "woman_val = glob.glob(r\"E:\\Z-Machine Learning\\My Work\\DataSets\\Gender Detection Through Images\\dataset1\\valid\\woman\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 36\n",
    "h = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1467.76it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 681.81it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 993.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1867.28it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 807.89it/s]\n",
      "100%|██████████| 170/170 [00:00<00:00, 1721.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "newImages = []\n",
    "y = []\n",
    "for image in tqdm(man_train):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(1)\n",
    "    \n",
    "for image in tqdm(man_test):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(1)\n",
    "    \n",
    "for image in tqdm(man_val):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(1)\n",
    "    \n",
    "    \n",
    "for image in tqdm(woman_train):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(0)\n",
    "for image in tqdm(woman_test):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(0)\n",
    "for image in tqdm(woman_val):\n",
    "    img = cv2.imread(image,0)\n",
    "    img = color.rgb2gray(img)\n",
    "    img = cv2.resize(img, (w,h ))\n",
    "    newImages.append(img)\n",
    "    y.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "newImages = np.array(newImages)\n",
    "newImages = newImages/255\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2280, 36, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(36,36, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 34, 34, 128)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 32)          18464     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 119,201\n",
      "Trainable params: 119,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(newImages, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1824, 36, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(-1, w, h, 1)\n",
    "x_test = np.array(x_test).reshape(-1, w, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1824, 36, 36, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.6893 - acc: 0.5280 - val_loss: 0.6604 - val_acc: 0.7039\n",
      "Epoch 2/40\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.5739 - acc: 0.6968 - val_loss: 0.5137 - val_acc: 0.7588\n",
      "Epoch 3/40\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.4688 - acc: 0.7747 - val_loss: 0.4410 - val_acc: 0.8070\n",
      "Epoch 4/40\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.3744 - acc: 0.8339 - val_loss: 0.3842 - val_acc: 0.8377\n",
      "Epoch 5/40\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.3003 - acc: 0.8816 - val_loss: 0.2859 - val_acc: 0.8816\n",
      "Epoch 6/40\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.2460 - acc: 0.9019 - val_loss: 0.2811 - val_acc: 0.8904\n",
      "Epoch 7/40\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.2180 - acc: 0.9205 - val_loss: 0.2731 - val_acc: 0.8794\n",
      "Epoch 8/40\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.2044 - acc: 0.9216 - val_loss: 0.2231 - val_acc: 0.9145\n",
      "Epoch 9/40\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 0.1651 - acc: 0.9435 - val_loss: 0.2129 - val_acc: 0.9254\n",
      "Epoch 10/40\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.1453 - acc: 0.9490 - val_loss: 0.2418 - val_acc: 0.9057\n",
      "Epoch 11/40\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1399 - acc: 0.9474 - val_loss: 0.2292 - val_acc: 0.9211\n",
      "Epoch 12/40\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1257 - acc: 0.9545 - val_loss: 0.1986 - val_acc: 0.9342\n",
      "Epoch 13/40\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1261 - acc: 0.9512 - val_loss: 0.2016 - val_acc: 0.9320\n",
      "Epoch 14/40\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0989 - acc: 0.9627 - val_loss: 0.2226 - val_acc: 0.9276\n",
      "Epoch 15/40\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.0718 - acc: 0.9742 - val_loss: 0.2246 - val_acc: 0.9342\n",
      "Epoch 16/40\n",
      "57/57 [==============================] - 3s 59ms/step - loss: 0.0706 - acc: 0.9764 - val_loss: 0.2230 - val_acc: 0.9298\n",
      "Epoch 17/40\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.0521 - acc: 0.9852 - val_loss: 0.2308 - val_acc: 0.9298\n",
      "Epoch 18/40\n",
      "57/57 [==============================] - 3s 60ms/step - loss: 0.0390 - acc: 0.9890 - val_loss: 0.2078 - val_acc: 0.9386\n",
      "Epoch 19/40\n",
      "57/57 [==============================] - 3s 61ms/step - loss: 0.0342 - acc: 0.9901 - val_loss: 0.2232 - val_acc: 0.9430\n",
      "Epoch 20/40\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.0288 - acc: 0.9929 - val_loss: 0.2720 - val_acc: 0.9342\n",
      "Epoch 21/40\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0314 - acc: 0.9896 - val_loss: 0.2444 - val_acc: 0.9364\n",
      "Epoch 22/40\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0269 - acc: 0.9934 - val_loss: 0.2942 - val_acc: 0.9276\n",
      "Epoch 23/40\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0271 - acc: 0.9890 - val_loss: 0.2681 - val_acc: 0.9298\n",
      "Epoch 24/40\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.0265 - acc: 0.9907 - val_loss: 0.2570 - val_acc: 0.9386\n",
      "Epoch 25/40\n",
      "57/57 [==============================] - 3s 57ms/step - loss: 0.0104 - acc: 0.9989 - val_loss: 0.2811 - val_acc: 0.9430\n",
      "Epoch 26/40\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.0092 - acc: 0.9984 - val_loss: 0.2652 - val_acc: 0.9430\n",
      "Epoch 27/40\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 0.0079 - acc: 0.9995 - val_loss: 0.2966 - val_acc: 0.9430\n",
      "Epoch 28/40\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.3053 - val_acc: 0.9452\n",
      "Epoch 29/40\n",
      "57/57 [==============================] - 3s 60ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.9364\n",
      "Epoch 30/40\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 0.9452\n",
      "Epoch 31/40\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.3224 - val_acc: 0.9430\n",
      "Epoch 32/40\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3240 - val_acc: 0.9452\n",
      "Epoch 33/40\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3313 - val_acc: 0.9408\n",
      "Epoch 34/40\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 9.4537e-04 - acc: 1.0000 - val_loss: 0.3337 - val_acc: 0.9408\n",
      "Epoch 35/40\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 8.7271e-04 - acc: 1.0000 - val_loss: 0.3410 - val_acc: 0.9408\n",
      "Epoch 36/40\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 7.8802e-04 - acc: 1.0000 - val_loss: 0.3425 - val_acc: 0.9408\n",
      "Epoch 37/40\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 7.0231e-04 - acc: 1.0000 - val_loss: 0.3491 - val_acc: 0.9408\n",
      "Epoch 38/40\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 6.4531e-04 - acc: 1.0000 - val_loss: 0.3488 - val_acc: 0.9408\n",
      "Epoch 39/40\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 6.0659e-04 - acc: 1.0000 - val_loss: 0.3593 - val_acc: 0.9408\n",
      "Epoch 40/40\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 5.8127e-04 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9408\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.binary_crossentropy, metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=40, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
